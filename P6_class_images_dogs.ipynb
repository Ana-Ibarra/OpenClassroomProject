{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "P6_class_images_dogs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ana-Ibarra/OpenClassroomProject/blob/alexnet_modified/P6_class_images_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRREppn4PrOs"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import History \n",
        "from pathlib import Path\n",
        "history = History()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzHZG5qeQ9BU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf2cfdf-c457-4f14-fb8d-9a11f959deb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oTBUdkjSJEW"
      },
      "source": [
        "### Images are converted to squared form and saved in two folders: train and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ShSuyO1rTIx"
      },
      "source": [
        "AS a first step, I changed the form of images, creating only sqared images, adding black parts to fullfil when rectangles. Then I saved them in \"images_squared\" folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKQVbwqvNZIW"
      },
      "source": [
        "# def make_square(im, fill_color=(0, 0, 0, 0)):\n",
        "#     x, y = im.size\n",
        "#     size = max(x, y)\n",
        "#     new_im = Image.new('RGB', (size, size), fill_color)\n",
        "#     new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "#     return new_im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewgcEMZvqPvT"
      },
      "source": [
        "# fpath2 = \"C:/Users/TorresIbarra/Desktop/MOOCs Ibarra/Openclassrooms/P6_IBARRA_Ana/images_squared\"\n",
        "# for index, category in enumerate(categories):\n",
        "#     print(index, category) \n",
        "#     os.mkdir(fpath2+\"/\"+category)\n",
        "#     for image_name in os.listdir(fpath+\"/\"+category): \n",
        "#         img = Image.open(fpath+\"/\"+category+\"/\"+image_name)\n",
        "#         file_type = img.format\n",
        "#         if img.size[0]!=img.size[1]:\n",
        "#             img = make_square(img)\n",
        "#         img.save(fpath2+\"/\"+category+\"/\"+image_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU9Pak_OsZ8x"
      },
      "source": [
        "# fpath = \"/content/drive/My Drive/OC_P6_images/images_squared/\"\r\n",
        "# for index, category in enumerate(categories):\r\n",
        "#     print(index, category) \r\n",
        "#     os.mkdir(fpath2+\"/\"+category)\r\n",
        "#     for image_name in os.listdir(fpath+\"/\"+category): \r\n",
        "#         img = Image.open(fpath+\"/\"+category+\"/\"+image_name)\r\n",
        "#         file_type = img.format\r\n",
        "#         if img.size[0]!=img.size[1]:\r\n",
        "#             img = make_square(img)\r\n",
        "#         img.save(fpath2+\"/\"+category+\"/\"+image_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM0f0LJQVu63"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sLSi-AxPrPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc52d35-d900-487b-f1a9-a2e7abd09d32"
      },
      "source": [
        "fpath = \"/content/drive/My Drive/OC_P6_images/images_squared_split/\"\n",
        "random_seed = 42\n",
        "squared_size = 224\n",
        "batch_size = 64\n",
        "categories = os.listdir(fpath+\"train\")\n",
        "print(\"List of categories = \", categories,\"\\n\\nNo. of categories = \", len(categories))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of categories =  ['n02087046-toy_terrier', 'n02085782-Japanese_spaniel', 'n02086079-Pekinese', 'n02086646-Blenheim_spaniel', 'n02086240-Shih-Tzu', 'n02085620-Chihuahua', 'n02088094-Afghan_hound', 'n02087394-Rhodesian_ridgeback', 'n02085936-Maltese_dog', 'n02086910-papillon', 'n02088238-basset', 'n02088466-bloodhound', 'n02088364-beagle', 'n02088632-bluetick', 'n02089867-Walker_hound', 'n02089078-black-and-tan_coonhound', 'n02089973-English_foxhound', 'n02090379-redbone', 'n02090622-borzoi', 'n02090721-Irish_wolfhound', 'n02091244-Ibizan_hound', 'n02091032-Italian_greyhound', 'n02091467-Norwegian_elkhound', 'n02091635-otterhound', 'n02091134-whippet', 'n02091831-Saluki', 'n02092002-Scottish_deerhound', 'n02092339-Weimaraner', 'n02093428-American_Staffordshire_terrier', 'n02093256-Staffordshire_bullterrier', 'n02093647-Bedlington_terrier', 'n02093859-Kerry_blue_terrier', 'n02093754-Border_terrier', 'n02094258-Norwich_terrier', 'n02094114-Norfolk_terrier', 'n02093991-Irish_terrier', 'n02095314-wire-haired_fox_terrier', 'n02094433-Yorkshire_terrier', 'n02095570-Lakeland_terrier', 'n02095889-Sealyham_terrier', 'n02096051-Airedale', 'n02096177-cairn', 'n02096437-Dandie_Dinmont', 'n02096294-Australian_terrier', 'n02096585-Boston_bull', 'n02097047-miniature_schnauzer', 'n02097209-standard_schnauzer', 'n02097130-giant_schnauzer', 'n02097298-Scotch_terrier', 'n02097474-Tibetan_terrier', 'n02097658-silky_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02098286-West_Highland_white_terrier', 'n02098413-Lhasa', 'n02099429-curly-coated_retriever', 'n02099267-flat-coated_retriever', 'n02099601-golden_retriever', 'n02099712-Labrador_retriever', 'n02099849-Chesapeake_Bay_retriever', 'n02100236-German_short-haired_pointer', 'n02100583-vizsla', 'n02100735-English_setter', 'n02101388-Brittany_spaniel', 'n02100877-Irish_setter', 'n02101006-Gordon_setter', 'n02101556-clumber', 'n02102040-English_springer', 'n02102177-Welsh_springer_spaniel', 'n02102318-cocker_spaniel', 'n02102480-Sussex_spaniel', 'n02102973-Irish_water_spaniel', 'n02104365-schipperke', 'n02104029-kuvasz', 'n02105056-groenendael', 'n02105412-kelpie', 'n02105251-briard', 'n02105162-malinois', 'n02105641-Old_English_sheepdog', 'n02105505-komondor', 'n02105855-Shetland_sheepdog', 'n02106030-collie', 'n02106382-Bouvier_des_Flandres', 'n02106166-Border_collie', 'n02106662-German_shepherd', 'n02106550-Rottweiler', 'n02107142-Doberman', 'n02107312-miniature_pinscher', 'n02107574-Greater_Swiss_Mountain_dog', 'n02107683-Bernese_mountain_dog', 'n02107908-Appenzeller', 'n02108000-EntleBucher', 'n02108089-boxer', 'n02108422-bull_mastiff', 'n02108551-Tibetan_mastiff', 'n02108915-French_bulldog', 'n02109047-Great_Dane', 'n02109525-Saint_Bernard', 'n02110063-malamute', 'n02109961-Eskimo_dog', 'n02110185-Siberian_husky', 'n02110627-affenpinscher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-Leonberg', 'n02111277-Newfoundland', 'n02111500-Great_Pyrenees', 'n02111889-Samoyed', 'n02112137-chow', 'n02112018-Pomeranian', 'n02112350-keeshond', 'n02112706-Brabancon_griffon', 'n02113186-Cardigan', 'n02113023-Pembroke', 'n02113712-miniature_poodle', 'n02113624-toy_poodle', 'n02113799-standard_poodle', 'n02113978-Mexican_hairless', 'n02115641-dingo', 'n02115913-dhole', 'n02116738-African_hunting_dog'] \n",
            "\n",
            "No. of categories =  120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4t-sIr5k7JW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53af8bad-6b7a-474a-a34e-403c25033dbc"
      },
      "source": [
        "train_ds = keras.preprocessing.image_dataset_from_directory(fpath+\"train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=(squared_size, squared_size),\n",
        "    shuffle=True,\n",
        "    seed=1,\n",
        "    validation_split=0.25,\n",
        "    subset=\"training\",\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16501 files belonging to 120 classes.\n",
            "Using 12376 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su4nBfvtiE_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d6d1f3-3b8e-41a7-e314-282f8b9b328d"
      },
      "source": [
        "len(train_ds)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0J5kMIgXLtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbdf98a-6b9a-4e51-f7d5-e8f0e07f3e3e"
      },
      "source": [
        "val_ds = keras.preprocessing.image_dataset_from_directory(fpath+\"train\",\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode='int',\r\n",
        "    class_names=None,\r\n",
        "    color_mode=\"rgb\",\r\n",
        "    batch_size=batch_size,\r\n",
        "    image_size=(squared_size, squared_size),\r\n",
        "    shuffle=True,\r\n",
        "    seed=1,\r\n",
        "    validation_split=0.25,\r\n",
        "    subset=\"validation\",\r\n",
        "    interpolation=\"bilinear\",\r\n",
        "    follow_links=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16501 files belonging to 120 classes.\n",
            "Using 4125 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvuY38k5Rroo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e83ec2a-98bc-4a5d-a91f-b6fe2032a044"
      },
      "source": [
        "test_ds = keras.preprocessing.image_dataset_from_directory(fpath+\"test\",\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode='int',\r\n",
        "    class_names=None,\r\n",
        "    color_mode=\"rgb\",\r\n",
        "    batch_size=batch_size,\r\n",
        "    image_size=(squared_size, squared_size),\r\n",
        "    shuffle=True,\r\n",
        "    seed=1,\r\n",
        "    validation_split=None,\r\n",
        "    subset=None,\r\n",
        "    interpolation=\"bilinear\",\r\n",
        "    follow_links=False,\r\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4080 files belonging to 120 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvdbdgHiUuU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df2b53b-3580-4ec7-d3d5-4287ba6bf545"
      },
      "source": [
        "class_names = train_ds.class_names\r\n",
        "print(\"No of classes in Training dataset: \", len(class_names))\r\n",
        "class_names = val_ds.class_names\r\n",
        "print(\"No of classes in Validation dataset: \", len(class_names))\r\n",
        "class_names = test_ds.class_names\r\n",
        "print(\"No of classes in Test dataset: \", len(class_names))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of classes in Training dataset:  120\n",
            "No of classes in Validation dataset:  120\n",
            "No of classes in Test dataset:  120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ4hBi_lYZJp"
      },
      "source": [
        "# for images, labels in train_ds:\r\n",
        "#   print(images.shape)\r\n",
        "#   print(labels.shape)\r\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU_f5uDt3sKa"
      },
      "source": [
        "Configure the dataset for performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cqtNz9E3kbb"
      },
      "source": [
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\r\n",
        "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH-HbHjTBNmx"
      },
      "source": [
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\r\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\r\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\r\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILrucLk-me6-"
      },
      "source": [
        "# AlexNet CNN model\n",
        "\n",
        "The architecture consists of eight layers: five convolutional layers and three fully-connected layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzudPojZPrRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0926fa8b-cdf0-4e46-f589-29dacb3cdc3d"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional layer\n",
        "model.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",\n",
        "                 activation=\"relu\",input_shape=(squared_size,squared_size,3)))\n",
        "# Normalisation\n",
        "# model.add(keras.layers.experimental.preprocessing.Rescaling(1./255))\n",
        "# Apply random data augmentation\n",
        "model.add(keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"))\n",
        "model.add(keras.layers.experimental.preprocessing.RandomRotation(0.1))\n",
        "model.add(keras.layers.experimental.preprocessing.RandomTranslation(0.1,0.1))\n",
        "# model.add(keras.layers.experimental.preprocessing.RandomContrast(0.1))\n",
        "# Max pool layer\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional layer\n",
        "model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),\n",
        "                 padding=\"valid\",activation=\"relu\"))\n",
        "# Max pool layer\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional layer\n",
        "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),\n",
        "                 padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "# 4th Convolutional layer\n",
        "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),\n",
        "                 padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "# 5th Convolutional layer\n",
        "model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),\n",
        "                 padding=\"valid\",activation=\"relu\"))\n",
        "# Max pool layer\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "\n",
        "# 1st Dense layer\n",
        "model.add(Dense(4096,input_shape=(squared_size,squared_size,3),\n",
        "                activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense layer\n",
        "model.add(Dense(4096,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense layer\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(len(categories),activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "random_flip (RandomFlip)     (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "random_rotation (RandomRotat (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "random_translation (RandomTr (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 22, 22, 256)       614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10, 10, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 120)               120120    \n",
            "=================================================================\n",
            "Total params: 25,837,504\n",
            "Trainable params: 25,817,904\n",
            "Non-trainable params: 19,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zeo5s556PrRo"
      },
      "source": [
        "# Compile the CNN model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "commit = \"AlexNet_dataAugmTrans\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq2gQFJ30sZK"
      },
      "source": [
        "epochs=100\r\n",
        "\r\n",
        "callback_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\r\n",
        "\r\n",
        "checkpoint_filepath = '/tmp/checkpoint'\r\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_filepath,\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max',\r\n",
        "    save_best_only=True)\r\n",
        "\r\n",
        "# model.load_weights(checkpoint_filepath)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZt9LaaeZ3jB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d939a2f7-6d0f-4c11-cb10-d876eb21a605"
      },
      "source": [
        "%%time\n",
        "history = model.fit(train_ds, validation_data = val_ds, epochs=epochs, callbacks=[callback_stop, model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 86/194 [============>.................] - ETA: 38:36 - loss: 5.4464 - accuracy: 0.0147"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPZxxvqKiL9"
      },
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "# Save neural network structure\r\n",
        "model_structure = model.to_json()\r\n",
        "f = Path(\"model_structure.json\")\r\n",
        "f.write_text(model_structure)\r\n",
        "\r\n",
        "# Save neural network's trined weights\r\n",
        "# model.sample_weights(model_weights.h5)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "DYCH5fPxAmG9",
        "outputId": "38cc0ef0-74cf-4189-9186-6773709f37b3"
      },
      "source": [
        "# model.load_weights(checkpoint_filepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3f92b3ade396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVWqN_SNrWfK"
      },
      "source": [
        "model.save(str(\"/content/drive/My Drive/OC_P6_images/images_squared_split/model\"+commit+\".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZK6DUDrJRAp"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxFs8A2b38JX"
      },
      "source": [
        "# model = load_model(str(\"/content/drive/My Drive/OC_P6_images/model\"+commit+\".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4OOrCoF8rq9"
      },
      "source": [
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "epochs=len(acc)\r\n",
        "epochs_range = range(epochs)\r\n",
        "\r\n",
        "plt.figure(figsize=(8, 8))\r\n",
        "plt.subplot(1, 2, 1)\r\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\r\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.title('Training and Validation Accuracy')\r\n",
        "\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\r\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.title('Training and Validation Loss')\r\n",
        "plt.show()\r\n",
        "plt.savefig(str(\"/content/drive/My Drive/OC_P6_images/Acc_Loss_\"+commit))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch9Iw8d2tyQ0"
      },
      "source": [
        "%%time\r\n",
        "history = model.fit(train_ds, validation_data = val_ds, epochs=10, callbacks=[callback_stop, model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx1gohzN9emn"
      },
      "source": [
        "# loaded_model = tf.keras.models.load_model(str(\"/content/drive/My Drive/OC_P6_images/model\"+commit+\".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLvONjPaZ8cW"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print(loss,accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdl812O1Cxgv"
      },
      "source": [
        "### Pre-trained\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH6dxgbaCki9"
      },
      "source": [
        "Now we're going to change to another CNN pre-trained. First, resize the images, because now we need size=150."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hACyrltoZHyv"
      },
      "source": [
        "squared_size = 150\n",
        "images, labels = read_resize(squared_size);\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(\"images shape:\",images.shape)\n",
        "print(\"labels shape:\",labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkLIsgYJTua_"
      },
      "source": [
        "# from tensorflow.keras import layers\n",
        "# data_augmentation = keras.Sequential(\n",
        "#         [layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "#          layers.experimental.preprocessing.RandomRotation(0.1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vPcj_Zxhzhy"
      },
      "source": [
        "# import numpy as np\r\n",
        "\r\n",
        "# for images, labels in train_ds.take(1):\r\n",
        "#     plt.figure(figsize=(10, 10))\r\n",
        "#     first_image = images[0]\r\n",
        "#     for i in range(9):\r\n",
        "#         ax = plt.subplot(3, 3, i + 1)\r\n",
        "#         augmented_image = data_augmentation(\r\n",
        "#             tf.expand_dims(first_image, 0), training=True\r\n",
        "#         )\r\n",
        "#         plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\r\n",
        "#         plt.title(int(labels[i]))\r\n",
        "#         plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq04endqV9fz"
      },
      "source": [
        "# tf.keras.application.Xception.preprocessinginput"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khrB-AxJNl2Z"
      },
      "source": [
        "base_model = keras.applications.Xception(\n",
        "             weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "             input_shape=(squared_size, squared_size, 3),\n",
        "             include_top=False)\n",
        "\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = keras.Input(shape=(squared_size, squared_size, 3))\n",
        "\n",
        "# Apply random data augmentation\n",
        "x = data_augmentation(inputs)  \n",
        "\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dense(1024, activation= \"relu\")(x)\n",
        "# Regularize with dropout\n",
        "x = keras.layers.Dropout(0.2)(x)  \n",
        "outputs = keras.layers.Dense(len(categories),activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl0jmJ4ReYd2"
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\", \n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data = (x_valid, y_valid), steps_per_epoch=35, epochs=20) # automatique\n",
        "# history2 = model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB3ziGclfCnb"
      },
      "source": [
        "# Unfreeze the base_model\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history2 = model.fit(x_train, y_train, validation_data = (x_valid, y_valid), steps_per_epoch=20, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}