{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P6_class_images_dogs_pretrained.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOA26Q1QOk3kD80s3wRIcm8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ana-Ibarra/OpenClassroomProject/blob/Pretrained/P6_class_images_dogs_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRREppn4PrOs"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import History \n",
        "history = History()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzHZG5qeQ9BU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da00417b-36bb-4d1c-984f-70fc9dadd49d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRcwvqblmvP"
      },
      "source": [
        "fpath = \"/content/drive/My Drive/OC_P6_images/images_squared/\"\r\n",
        "random_seed = 42\r\n",
        "squared_size = 150\r\n",
        "batch_size = 32\r\n",
        "categories = os.listdir(fpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4t-sIr5k7JW",
        "outputId": "819d67b0-6596-4d4c-a515-73fa21ef0dc5"
      },
      "source": [
        "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    fpath,\n",
        "    labels=\"inferred\",\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=(squared_size, squared_size),\n",
        "    shuffle=True,\n",
        "    seed=1,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20581 files belonging to 120 classes.\n",
            "Using 16465 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su4nBfvtiE_K",
        "outputId": "c3fadb99-de7f-4793-c1c7-3b0c80ef2b29"
      },
      "source": [
        "len(train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0J5kMIgXLtX",
        "outputId": "e00e0bbf-39d1-401d-d12a-6d4339100cdd"
      },
      "source": [
        "val_ds = keras.preprocessing.image_dataset_from_directory(\r\n",
        "    fpath,\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode='int',\r\n",
        "    class_names=None,\r\n",
        "    color_mode=\"rgb\",\r\n",
        "    batch_size=batch_size,\r\n",
        "    image_size=(squared_size, squared_size),\r\n",
        "    shuffle=True,\r\n",
        "    seed=1,\r\n",
        "    validation_split=0.2,\r\n",
        "    subset=\"validation\",\r\n",
        "    interpolation=\"bilinear\",\r\n",
        "    follow_links=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20581 files belonging to 120 classes.\n",
            "Using 4116 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU_f5uDt3sKa"
      },
      "source": [
        "Configure the dataset for performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cqtNz9E3kbb"
      },
      "source": [
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\r\n",
        "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raOR5_osaDJL"
      },
      "source": [
        "# x, x_test, y, y_test = train_test_split(train_ds, \n",
        "#                                   test_size = 0.25, train_size=0.75, \n",
        "#                                   random_state = random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkLIsgYJTua_"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "data_augmentation = keras.Sequential(\n",
        "        [layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "         layers.experimental.preprocessing.RandomRotation(0.1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vPcj_Zxhzhy"
      },
      "source": [
        "# import numpy as np\r\n",
        "\r\n",
        "# for images, labels in train_ds.take(1):\r\n",
        "#     plt.figure(figsize=(10, 10))\r\n",
        "#     first_image = images[0]\r\n",
        "#     for i in range(9):\r\n",
        "#         ax = plt.subplot(3, 3, i + 1)\r\n",
        "#         augmented_image = data_augmentation(\r\n",
        "#             tf.expand_dims(first_image, 0), training=True\r\n",
        "#         )\r\n",
        "#         plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\r\n",
        "#         plt.title(int(labels[i]))\r\n",
        "#         plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq04endqV9fz"
      },
      "source": [
        "# tf.keras.application.Xception.preprocessinginput"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khrB-AxJNl2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1091e058-64d6-4d81-89d6-42725ff28208"
      },
      "source": [
        "base_model = keras.applications.Xception(\n",
        "             weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "             input_shape=(squared_size, squared_size, 3),\n",
        "             include_top=False)\n",
        "\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = keras.Input(shape=(squared_size, squared_size, 3))\n",
        "\n",
        "# Preprocess for input images as xception base model\n",
        "x = keras.applications.xception.preprocess_input(inputs)\n",
        "\n",
        "# Apply random data augmentation\n",
        "x = data_augmentation(x)  \n",
        "\n",
        "# Normalisation\n",
        "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
        "mean = np.array([127.5] * 3)\n",
        "var = mean ** 2\n",
        "# Scale inputs to [-1, +1]\n",
        "x = norm_layer(x)\n",
        "norm_layer.set_weights([mean, var])\n",
        "\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dense(1024, activation= \"relu\")(x)\n",
        "\n",
        "# Regularize with dropout\n",
        "x = keras.layers.Dropout(0.2)(x)  \n",
        "outputs = keras.layers.Dense(len(categories),activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 150, 150, 3)       7         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               123000    \n",
            "=================================================================\n",
            "Total params: 23,082,663\n",
            "Trainable params: 2,221,176\n",
            "Non-trainable params: 20,861,487\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl0jmJ4ReYd2"
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\", \n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSq1AmJp4uD0"
      },
      "source": [
        "epochs=40\r\n",
        "\r\n",
        "callback_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\r\n",
        "checkpoint_filepath = '/tmp/checkpointPT'\r\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_filepath,\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max',\r\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUP9di4pY74u",
        "outputId": "81a57fa8-a284-48b8-9541-76eec81e3e36"
      },
      "source": [
        "%%time\r\n",
        "model.fit(train_ds, validation_data = val_ds, epochs=epochs, callbacks=[callback_stop, model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "210/515 [===========>..................] - ETA: 1:13:12 - loss: 4.7823 - accuracy: 0.0104"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "YBTRa2UbZE8_",
        "outputId": "c3044a9a-8436-4002-bd11-a488486acec1"
      },
      "source": [
        "# Unfreeze the base_model\r\n",
        "base_model.trainable = True\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\r\n",
        "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2660f59d9552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Unfreeze the base_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB3ziGclfCnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "2c0baf9c-fca4-442f-d8ed-4f0673f5a700"
      },
      "source": [
        "%%time\n",
        "history2 = model.fit(train_ds, validation_data = val_ds, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-4686453b5a84>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    %%time\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "w-CYauv_XaV-",
        "outputId": "1f8d8b2e-4df7-4cea-eb4e-0375bf1e7989"
      },
      "source": [
        "model = load_model(\"/content/drive/My Drive/OC_P6_images/classe120_dogs_alex_modifDo1.h5\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e40d444b2bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/OC_P6_images/classe120_dogs_alex_modifDo1.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McilPViR7bjP"
      },
      "source": [
        "acc = history.history2['accuracy']\r\n",
        "val_acc = history.history2['val_accuracy']\r\n",
        "\r\n",
        "loss = history.history2['loss']\r\n",
        "val_loss = history.history2['val_loss']\r\n",
        "epochs=len(acc)\r\n",
        "epochs_range = range(epochs)\r\n",
        "\r\n",
        "plt.figure(figsize=(8, 8))\r\n",
        "plt.subplot(1, 2, 1)\r\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\r\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.title('Training and Validation Accuracy')\r\n",
        "\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\r\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.title('Training and Validation Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}